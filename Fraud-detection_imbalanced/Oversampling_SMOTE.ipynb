{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context\n",
    "It is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase.\n",
    "\n",
    "### Content\n",
    "The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
    "\n",
    "### Goal\n",
    "Identify fraudulent credit card transactions in this highly imbalanced dataset using oversampling via SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T21:11:08.411403Z",
     "start_time": "2019-08-13T21:11:06.656338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset has 284807 data points with 31 variables each.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the dataset\n",
    "data0 = pd.read_csv('creditcard.csv')\n",
    "\n",
    "#prices = data['MEDV']\n",
    "#features = data.drop('MEDV', axis = 1)\n",
    "    \n",
    "# Success\n",
    "print(\"Test dataset has {} data points with {} variables each.\".format(*data0.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data were already checked for missing values in the EDA notebook. Next, I rescale the 'Amount' feature, drop the 'Time' feature, and reassemble the rescaled feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T21:11:08.532720Z",
     "start_time": "2019-08-13T21:11:08.519976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-fraudulent transactions 99.83 %\n",
      "fraudulent transactions 0.17 %\n"
     ]
    }
   ],
   "source": [
    "# Check how imbalanced the data is\n",
    "print('non-fraudulent transactions', round(data0['Class'].value_counts()[0]/len(data0) * 100,2), '%')\n",
    "print('fraudulent transactions', round(data0['Class'].value_counts()[1]/len(data0) * 100,2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T21:11:10.825108Z",
     "start_time": "2019-08-13T21:11:10.691032Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount_norm</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.244964</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.342475</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.160686</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.140534</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.073403</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Amount_norm        V1        V2        V3        V4        V5        V6  \\\n",
       "0     0.244964 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1    -0.342475  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2     1.160686 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3     0.140534 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4    -0.073403 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "\n",
       "         V7        V8        V9  ...       V20       V21       V22       V23  \\\n",
       "0  0.239599  0.098698  0.363787  ...  0.251412 -0.018307  0.277838 -0.110474   \n",
       "1 -0.078803  0.085102 -0.255425  ... -0.069083 -0.225775 -0.638672  0.101288   \n",
       "2  0.791461  0.247676 -1.514654  ...  0.524980  0.247998  0.771679  0.909412   \n",
       "3  0.237609  0.377436 -1.387024  ... -0.208038 -0.108300  0.005274 -0.190321   \n",
       "4  0.592941 -0.270533  0.817739  ...  0.408542 -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rescale 'Amount', drop 'Time' as it is not relevant for predicting fraud\n",
    "scaler = StandardScaler()\n",
    "data0['Amount_norm'] = scaler.fit_transform(data0['Amount'].values.reshape(-1, 1))\n",
    "\n",
    "# dataframe of the V-features only:\n",
    "v_data = data0.drop(['Amount_norm', 'Time', 'Amount'], axis=1)\n",
    "\n",
    "# New dataframe with the normalized Amount_norm as a first column, for convenience\n",
    "data = pd.concat([data0['Amount_norm'], v_data], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate the predictors and the dependent variable 'Class'. Split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T21:11:17.376936Z",
     "start_time": "2019-08-13T21:11:17.286719Z"
    }
   },
   "outputs": [],
   "source": [
    "# Separate the predictors from the dependent variable ('Class'):\n",
    "X = data.iloc[:, data.columns != 'Class']\n",
    "y = data.iloc[:, data.columns == 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T22:10:22.556984Z",
     "start_time": "2019-08-13T22:10:22.462997Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test datasets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T21:11:19.976790Z",
     "start_time": "2019-08-13T21:11:19.965694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-fraudulent transactions 99.82 %\n",
      "fraudulent transactions 0.18 %\n"
     ]
    }
   ],
   "source": [
    "# Check how imbalanced the training set is: it roughly retained the imbalance ratio from before splitting\n",
    "print('non-fraudulent transactions', round(y_train['Class'].value_counts()[0]/len(y_train) * 100,2), '%')\n",
    "print('fraudulent transactions', round(y_train['Class'].value_counts()[1]/len(y_train) * 100,2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, I chose to increase the number of points in the minority class using SMOTE. Import the method, and fit the training data (do NOT touch the test data!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T22:10:30.466699Z",
     "start_time": "2019-08-13T22:10:29.455887Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([227440, 227440])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smt = SMOTE()\n",
    "X_train, y_train = smt.fit_sample(X_train, y_train)\n",
    "np.bincount(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a logistic regression classifier to the (now balanced) training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T21:12:09.550272Z",
     "start_time": "2019-08-13T21:12:06.133228Z"
    }
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=1, solver='liblinear')\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred=logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T21:12:12.991518Z",
     "start_time": "2019-08-13T21:12:09.837464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.9787402127734279\n",
      "Recall =  0.8850574712643678\n"
     ]
    }
   ],
   "source": [
    "# How did we do?\n",
    "print('Accuracy = ', logreg.score(X_test, y_test))\n",
    "print('Recall = ', recall_score(y_test, logreg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I was aiming for high recall. Let's look at the metrics: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T21:12:20.509598Z",
     "start_time": "2019-08-13T21:12:20.410817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55674  1201]\n",
      " [   10    77]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     56875\n",
      "           1       0.06      0.89      0.11        87\n",
      "\n",
      "    accuracy                           0.98     56962\n",
      "   macro avg       0.53      0.93      0.55     56962\n",
      "weighted avg       1.00      0.98      0.99     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great! The recall score is 0.89."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, let's try a different classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T21:39:55.435788Z",
     "start_time": "2019-08-13T21:35:46.202819Z"
    }
   },
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T21:47:11.953311Z",
     "start_time": "2019-08-13T21:47:11.852042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56864    11]\n",
      " [   18    69]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56875\n",
      "           1       0.86      0.79      0.83        87\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.93      0.90      0.91     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:04:51.678231Z",
     "start_time": "2019-08-13T23:04:51.674798Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The random forest classifier resulted in a really high precision and reduced recall score compared to the logistic regression classifier. It was kind of slow, too - training it took > 4 minutes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try xgboost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T22:47:55.124672Z",
     "start_time": "2019-08-13T22:46:10.274073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost.sklearn import XGBClassifier  \n",
    "\n",
    "xclas = XGBClassifier()  # and for classifier  \n",
    "xclas.fit(X_train, y_train)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:05:49.671935Z",
     "start_time": "2019-08-13T23:05:49.498182Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "y_pred = xclas.predict(X_test.values)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:05:52.063104Z",
     "start_time": "2019-08-13T23:05:51.964114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56253   622]\n",
      " [   11    76]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     56875\n",
      "           1       0.11      0.87      0.19        87\n",
      "\n",
      "    accuracy                           0.99     56962\n",
      "   macro avg       0.55      0.93      0.59     56962\n",
      "weighted avg       1.00      0.99      0.99     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
